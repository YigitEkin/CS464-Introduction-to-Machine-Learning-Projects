{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>QUESTION 2 (Logistic Regression):</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initial Setup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing the dataset\n",
    "FILENAME = \"/projects/projects1/dataset.csv\"\n",
    "dataset = pd.read_csv(FILENAME)\n",
    "dataset = (dataset - dataset.min())/(dataset.max() - dataset.min())\n",
    "\n",
    "tau = []\n",
    "p = []\n",
    "g = []\n",
    "labels = []\n",
    "\n",
    "tau_validation = []\n",
    "p_validation = []\n",
    "g_validation = []\n",
    "labels_validation = []\n",
    "\n",
    "tau_train = []\n",
    "p_train = []\n",
    "g_train = []\n",
    "labels_train = []\n",
    "\n",
    "for i in range(int(len(dataset) * 0.7)):\n",
    "    for j in range(int(len(dataset.columns))):\n",
    "        if j < 4:\n",
    "            tau.append(dataset.iloc[i, j])\n",
    "        elif j < 8:\n",
    "            p.append(dataset.iloc[i, j])\n",
    "        elif j < 12:\n",
    "            g.append(dataset.iloc[i, j])\n",
    "        else:\n",
    "            labels.append(dataset.iloc[i, j])\n",
    "\n",
    "for i in range(int(len(dataset) * 0.7), int(len(dataset) * 0.8)):\n",
    "    for j in range(int(len(dataset.columns))):\n",
    "        if j < 4:\n",
    "            tau_validation.append(dataset.iloc[i, j])\n",
    "        elif j < 8:\n",
    "            p_validation.append(dataset.iloc[i, j])\n",
    "        elif j < 12:\n",
    "            g_validation.append(dataset.iloc[i, j])\n",
    "        else:\n",
    "            labels_validation.append(dataset.iloc[i, j])\n",
    "\n",
    "for i in range(int(len(dataset) * 0.8), len(dataset)):\n",
    "    for j in range(int(len(dataset.columns))):\n",
    "        if j < 4:\n",
    "            tau_train.append(dataset.iloc[i, j])\n",
    "        elif j < 8:\n",
    "            p_train.append(dataset.iloc[i, j])\n",
    "        elif j < 12:\n",
    "            g_train.append(dataset.iloc[i, j])\n",
    "        else:\n",
    "            labels_train.append(dataset.iloc[i, j])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "#define mcle for logistic regression without sklearn\n",
    "def mcle(tau,g,p, weights):\n",
    "    sum = weights[0]\n",
    "    for i in range(12):\n",
    "        if i < 4:\n",
    "            sum = sum + tau[i]* weights[i]\n",
    "        elif i < 8:\n",
    "            sum = sum + g[i - 4] * weights[i]\n",
    "        elif i < 12:\n",
    "            sum = sum + p[i - 8] * weights[i]\n",
    "    p_0 = 1/(1+np.exp(sum))\n",
    "    p_1 = sum / (1+np.exp(sum))\n",
    "    \n",
    "    return 1 if p_1 > p_0 else 0\n",
    "    \n",
    "#Define log likelihood function\n",
    "def log_likelihood(x, y, w):\n",
    "    return np.sum(y * np.dot(x, w) - np.log(1 + np.exp(np.dot(x, w))))\n",
    "\n",
    "#Define schotastic gradient ascent function\n",
    "def sga(tau,pg,p, y, w, alpha):\n",
    "    for i in range(len(tau)):\n",
    "        x = np.array([tau[i],pg[i],p[i]])\n",
    "        w = w + alpha * (y[i] - sigmoid(np.dot(x, w))) * x\n",
    "    return w + w0\n",
    "\n",
    "#Define full batch gradient ascent function\n",
    "def fga(tau,pg,p, y, w, alpha):\n",
    "    x = np.array([tau,pg,p])\n",
    "    w = w + alpha * np.dot((y - sigmoid(np.dot(x, w))), x)\n",
    "    return w \n",
    "\n",
    "#Define mini batch gradient ascent function\n",
    "def mba(tau,pg,p, y, w, alpha):\n",
    "    for i in range(0, len(tau), 10):\n",
    "        x = np.array([tau[i],pg[i],p[i]])\n",
    "        w = w + alpha * (y[i] - sigmoid(np.dot(x, w))) * x\n",
    "    return w \n",
    "\n",
    "def logistic_regression(tau,pg,p,y,w,lr,batch_size, w0):\n",
    "    if batch_size == 1:\n",
    "        w = sga(tau,pg,p,y,w,lr, w0)\n",
    "    elif batch_size == len(tau):\n",
    "        w = fga(tau,pg,p,y,w,lr, w0)\n",
    "    else:\n",
    "        w = mba(tau,pg,p,y,w,lr, w0)\n",
    "    return w + w0\n",
    "\n",
    "\n",
    "\n",
    "#Define the function to calculate the accuracy\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "#Define the function to calculate the precision and recall\n",
    "def precision_recall(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return precision, recall\n",
    "\n",
    "#Define the function to calculate the f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision, recall = precision_recall(y_true, y_pred)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "#Define the function to calculate the f2 score\n",
    "def f2_score(y_true, y_pred):\n",
    "    precision, recall = precision_recall(y_true, y_pred)\n",
    "    f2_score = (1 + 2**2) * (precision * recall) / ((2**2 * precision) + recall)\n",
    "    return f2_score\n",
    "\n",
    "#Define the function to calculate the confusion matrix\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    return np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "#Define the function to calculate the f0.5 score\n",
    "def f05_score(y_true, y_pred):\n",
    "    precision, recall = precision_recall(y_true, y_pred)\n",
    "    f05_score = (1 + 0.5**2) * (precision * recall) / ((0.5**2 * precision) + recall)\n",
    "    return f05_score\n",
    "\n",
    "#Define the function to calculate the false positive rate\n",
    "def false_positive_rate(y_true, y_pred):\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    return fp / (fp + tn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 2.1</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.normal(0, 1, 12)\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, 1, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 1)\n",
    "    print(\"Initial weights: \", w0)\n",
    "    \n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, 64, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 64)\n",
    "    print(\"Initial weights: \", w0)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, len(tau_train), w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", len(tau_train))\n",
    "    print(\"Initial weights: \", w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results <br/>\n",
    "<p>\n",
    "As it can be seen, stocasthic is more accurate and less batch size leads to a more accurate model.\n",
    "As batch size being larger corresponds to looking up more indexes to update the value, it increases the learning time. In other words, batch size is directly proportinal with training time.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 2.2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.uniform(0, 1, 12)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, 1, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 1)\n",
    "    print(\"Initial weights: \", w0)\n",
    "    \n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, 64, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 64)\n",
    "    print(\"Initial weights: \", w0)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, len(tau_train), w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", len(tau_train))\n",
    "    print(\"Initial weights: \", w0)\n",
    "\n",
    "w0 = np.zeros(0, 1, 12)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, 1, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 1)\n",
    "    print(\"Initial weights: \", w0)\n",
    "    \n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, 64, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 64)\n",
    "    print(\"Initial weights: \", w0)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w, 0.1, len(tau_train), w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", len(tau_train))\n",
    "    print(\"Initial weights: \", w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: <br/>\n",
    "<p>\n",
    "As initial weights is the starting point and you update the values from the starting points. If number of epochs are equal, then initial weights can change the accuracy of the model. A better initial weight is a better starting point.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 2.3</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.normal(0, 1, 12)\n",
    "\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w,0.1, 64, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 64)\n",
    "    print(\"Initial weights: \", w0)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w,0.001, 64, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 64)\n",
    "    print(\"Initial weights: \", w0)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w,0.0001, 64, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 64)\n",
    "    print(\"Initial weights: \", w0)\n",
    "\n",
    "\n",
    "for i in range(0, 100):\n",
    "    w = logistic_regression(tau_train, g_train, p_train, labels_train, w,0.00001, 64, w0)\n",
    "    y_pred = np.array([mcle(tau_validation, g_validation, p_validation, w) for i in range(len(tau_validation))])\n",
    "    print(\"Iteration: \", i, \"Accuracy: \", accuracy(labels_validation, y_pred), \"F1 score: \", f1_score(labels_validation, y_pred), \"F2 score: \", f2_score(labels_validation, y_pred), \"F0.5 score: \", f05_score(labels_validation, y_pred), \"False positive rate: \", false_positive_rate(labels_validation, y_pred), \"Confusion matrix: \", confusion_matrix(labels_validation, y_pred))\n",
    "    print(\"Weights: \", w)\n",
    "\n",
    "    print(\"Learning rate: \", 0.1)\n",
    "    print(\"Batch size: \", 64)\n",
    "    print(\"Initial weights: \", w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:<br/>\n",
    "<p>\n",
    "Learning rate is the rate in which the weights are being updated. In other words, learning rate is the rate in which the weight parameters are changing. Lesser learning rate results in a more precised learning process however it will need more epochs. As the number of epochs is not that high and the parameters are between 0 and 1, 10^-5 learning rate is too precise to update itself for 100 epochs. 10^-3 is more accurate as it learns in a more rapid way.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
